{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach to a univariate Long-Short-Term Memory model for predicting the solar output  #\n",
    "\n",
    "For our optimisation we need solar output predictions. In this notebook we will use a univariate Long-Short-Term Memory model to predict the solar output. \n",
    "\n",
    "\n",
    " https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install all the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from statsmodels.tsa.stattools import adfuller,kpss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "import statsmodels.graphics.tsaplots as tsaplot\n",
    "from statsmodels.tsa.holtwinters import Holt, ExponentialSmoothing, SimpleExpSmoothing\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential # intitialize the ANN\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM , Conv1D, MaxPooling1D  # create layers\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with loading the pickle file with our full dataset into this notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/final_dataframe.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are not very easy to work with and can be a bit hard to read. Therefore we will rename them to make them easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solar_generation_MWh</th>\n",
       "      <th>Solar_installed_MW</th>\n",
       "      <th>Total_consumption_MWh</th>\n",
       "      <th>DE_LU_price_per_MWh</th>\n",
       "      <th>normalisation_factor</th>\n",
       "      <th>Solar_generation_MWh_normalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>56.10</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 22:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12945.50</td>\n",
       "      <td>95.41</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12817.75</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12539.00</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12371.00</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12176.75</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163680 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Solar_generation_MWh  Solar_installed_MW   \n",
       "Date                                                            \n",
       "2018-10-01 00:00:00                   0.0             42805.0  \\\n",
       "2018-10-01 00:15:00                   0.0             42805.0   \n",
       "2018-10-01 00:30:00                   0.0             42805.0   \n",
       "2018-10-01 00:45:00                   0.0             42805.0   \n",
       "2018-10-01 01:00:00                   0.0             42805.0   \n",
       "...                                   ...                 ...   \n",
       "2023-06-01 22:45:00                   0.0             62579.0   \n",
       "2023-06-01 23:00:00                   0.0             62579.0   \n",
       "2023-06-01 23:15:00                   0.0             62579.0   \n",
       "2023-06-01 23:30:00                   0.0             62579.0   \n",
       "2023-06-01 23:45:00                   0.0             62579.0   \n",
       "\n",
       "                     Total_consumption_MWh  DE_LU_price_per_MWh   \n",
       "Date                                                              \n",
       "2018-10-01 00:00:00               10589.75                59.53  \\\n",
       "2018-10-01 00:15:00               10589.75                59.53   \n",
       "2018-10-01 00:30:00               10589.75                59.53   \n",
       "2018-10-01 00:45:00               10589.75                59.53   \n",
       "2018-10-01 01:00:00               10589.75                56.10   \n",
       "...                                    ...                  ...   \n",
       "2023-06-01 22:45:00               12945.50                95.41   \n",
       "2023-06-01 23:00:00               12817.75                86.53   \n",
       "2023-06-01 23:15:00               12539.00                86.53   \n",
       "2023-06-01 23:30:00               12371.00                86.53   \n",
       "2023-06-01 23:45:00               12176.75                86.53   \n",
       "\n",
       "                     normalisation_factor  Solar_generation_MWh_normalized  \n",
       "Date                                                                        \n",
       "2018-10-01 00:00:00              0.684015                              0.0  \n",
       "2018-10-01 00:15:00              0.684015                              0.0  \n",
       "2018-10-01 00:30:00              0.684015                              0.0  \n",
       "2018-10-01 00:45:00              0.684015                              0.0  \n",
       "2018-10-01 01:00:00              0.684015                              0.0  \n",
       "...                                   ...                              ...  \n",
       "2023-06-01 22:45:00              1.000000                              0.0  \n",
       "2023-06-01 23:00:00              1.000000                              0.0  \n",
       "2023-06-01 23:15:00              1.000000                              0.0  \n",
       "2023-06-01 23:30:00              1.000000                              0.0  \n",
       "2023-06-01 23:45:00              1.000000                              0.0  \n",
       "\n",
       "[163680 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def col_names(df):\n",
    "    ''' this function renames the columns to make them easier to read \n",
    "      additionally set the date as index in our dataframe'''\n",
    "    column_names = {'Photovoltaics [MWh] Original resolutions': 'Solar_generation_MWh',\n",
    "                'Photovoltaics [MW] Calculated resolutions': 'Solar_installed_MW',\n",
    "                'Total (grid load) [MWh] Original resolutions': 'Total_consumption_MWh',\n",
    "                'Germany/Luxembourg [â‚¬/MWh] Calculated resolutions': 'DE_LU_price_per_MWh',}\n",
    "    df.rename(columns=column_names, inplace=True)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    return df\n",
    "\n",
    "col_names(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can already split the data into train and test set. Important to note here is that the shuffle has to be false otherwise the split is not appropriate for time series analysis. I will use the previously defined approach from the 20230704_train_val_test_split notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have a huge problem with the 0 therfore I will add 1 to all my datapoints \n",
    "#df['Solar_generation_MWh_normalized'] = df['Solar_generation_MWh_normalized'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['Total_consumption_MWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_timeseries(df):\n",
    "    ''' In the first part we select the train and test data.\n",
    "    In the second per the columns we want to use for our predictions '''\n",
    "    \n",
    "    test = df[df.index >= '2022-06-01']\n",
    "    train = df[df.index < '2022-06-01']\n",
    "\n",
    "    # now we select the columns we want to use for our predictions\n",
    "\n",
    "    test = test[['Total_consumption_MWh']]\n",
    "    train = train[['Total_consumption_MWh']]\n",
    "    return test, train\n",
    "\n",
    "test, train = test_train_timeseries(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively we could also use \n",
    "#train, test = train_test_split(df[['Solar_generation_MWh_normalized']], test_size=.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_consumption_MWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:00:00</th>\n",
       "      <td>11317.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:15:00</th>\n",
       "      <td>11203.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:30:00</th>\n",
       "      <td>11089.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:45:00</th>\n",
       "      <td>10982.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 01:00:00</th>\n",
       "      <td>10934.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 22:45:00</th>\n",
       "      <td>12945.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:00:00</th>\n",
       "      <td>12817.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:15:00</th>\n",
       "      <td>12539.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:30:00</th>\n",
       "      <td>12371.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:45:00</th>\n",
       "      <td>12176.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35136 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Total_consumption_MWh\n",
       "Date                                      \n",
       "2022-06-01 00:00:00               11317.75\n",
       "2022-06-01 00:15:00               11203.75\n",
       "2022-06-01 00:30:00               11089.00\n",
       "2022-06-01 00:45:00               10982.75\n",
       "2022-06-01 01:00:00               10934.50\n",
       "...                                    ...\n",
       "2023-06-01 22:45:00               12945.50\n",
       "2023-06-01 23:00:00               12817.75\n",
       "2023-06-01 23:15:00               12539.00\n",
       "2023-06-01 23:30:00               12371.00\n",
       "2023-06-01 23:45:00               12176.75\n",
       "\n",
       "[35136 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_consumption_MWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:00:00</th>\n",
       "      <td>10589.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:15:00</th>\n",
       "      <td>10589.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:30:00</th>\n",
       "      <td>10589.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:45:00</th>\n",
       "      <td>10589.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 01:00:00</th>\n",
       "      <td>10589.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31 22:45:00</th>\n",
       "      <td>12692.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31 23:00:00</th>\n",
       "      <td>12446.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31 23:15:00</th>\n",
       "      <td>12243.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31 23:30:00</th>\n",
       "      <td>12065.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31 23:45:00</th>\n",
       "      <td>11890.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128544 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Total_consumption_MWh\n",
       "Date                                      \n",
       "2018-10-01 00:00:00               10589.75\n",
       "2018-10-01 00:15:00               10589.75\n",
       "2018-10-01 00:30:00               10589.75\n",
       "2018-10-01 00:45:00               10589.75\n",
       "2018-10-01 01:00:00               10589.75\n",
       "...                                    ...\n",
       "2022-05-31 22:45:00               12692.00\n",
       "2022-05-31 23:00:00               12446.50\n",
       "2022-05-31 23:15:00               12243.50\n",
       "2022-05-31 23:30:00               12065.50\n",
       "2022-05-31 23:45:00               11890.50\n",
       "\n",
       "[128544 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I worked nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's scale the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data for the model #! Test MinMaxScaler \n",
    "\n",
    "scaler = StandardScaler()\n",
    "train['Total_consumption_MWh'] = scaler.fit_transform(train[['Total_consumption_MWh']])\n",
    "test['Total_consumption_MWh'] = scaler.transform(test[['Total_consumption_MWh']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_consumption_MWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:00:00</th>\n",
       "      <td>-1.231615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:15:00</th>\n",
       "      <td>-1.277501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:30:00</th>\n",
       "      <td>-1.323690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 00:45:00</th>\n",
       "      <td>-1.366457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01 01:00:00</th>\n",
       "      <td>-1.385878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 22:45:00</th>\n",
       "      <td>-0.576425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:00:00</th>\n",
       "      <td>-0.627846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:15:00</th>\n",
       "      <td>-0.740046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:30:00</th>\n",
       "      <td>-0.807668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:45:00</th>\n",
       "      <td>-0.885856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35136 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Total_consumption_MWh\n",
       "Date                                      \n",
       "2022-06-01 00:00:00              -1.231615\n",
       "2022-06-01 00:15:00              -1.277501\n",
       "2022-06-01 00:30:00              -1.323690\n",
       "2022-06-01 00:45:00              -1.366457\n",
       "2022-06-01 01:00:00              -1.385878\n",
       "...                                    ...\n",
       "2023-06-01 22:45:00              -0.576425\n",
       "2023-06-01 23:00:00              -0.627846\n",
       "2023-06-01 23:15:00              -0.740046\n",
       "2023-06-01 23:30:00              -0.807668\n",
       "2023-06-01 23:45:00              -0.885856\n",
       "\n",
       "[35136 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samller samples to feed into the LSTM\n",
    "def split_sequence(input, n_steps, pred_size):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(input)):\n",
    "        end_ix = i + n_steps # find the end of this pattern\n",
    "        if end_ix+pred_size > len(input)-1: # check if we are beyond the sequence\n",
    "            break\n",
    "        seq_x, seq_y = input[i:end_ix], input[end_ix: end_ix+pred_size]# gather input and output parts of the pattern\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.squeeze(np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127776 127776\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "input = train['Total_consumption_MWh']\n",
    "# choose a number of time steps\n",
    "n_steps = 672\n",
    "# prediction size \n",
    "pred_size= 96\n",
    "# split into samples\n",
    "X, y = split_sequence(input, n_steps, pred_size)\n",
    "# summarize the data\n",
    "print(len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.23161488],\n",
       "        [-1.27750133],\n",
       "        [-1.32368967],\n",
       "        ...,\n",
       "        [-0.89913933],\n",
       "        [-0.98728963],\n",
       "        [-1.06467271]],\n",
       "\n",
       "       [[-1.27750133],\n",
       "        [-1.32368967],\n",
       "        [-1.36645665],\n",
       "        ...,\n",
       "        [-0.98728963],\n",
       "        [-1.06467271],\n",
       "        [-1.15221923]],\n",
       "\n",
       "       [[-1.32368967],\n",
       "        [-1.36645665],\n",
       "        [-1.3858779 ],\n",
       "        ...,\n",
       "        [-1.06467271],\n",
       "        [-1.15221923],\n",
       "        [-1.22155206]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.98618272],\n",
       "        [-1.0407232 ],\n",
       "        [-1.10200577],\n",
       "        ...,\n",
       "        [-0.5253056 ],\n",
       "        [-0.60550627],\n",
       "        [-0.71690167]],\n",
       "\n",
       "       [[-1.0407232 ],\n",
       "        [-1.10200577],\n",
       "        [-1.1906592 ],\n",
       "        ...,\n",
       "        [-0.60550627],\n",
       "        [-0.71690167],\n",
       "        [-0.78402068]],\n",
       "\n",
       "       [[-1.10200577],\n",
       "        [-1.1906592 ],\n",
       "        [-1.25043235],\n",
       "        ...,\n",
       "        [-0.71690167],\n",
       "        [-0.78402068],\n",
       "        [-0.86542889]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = split_sequence(test['Total_consumption_MWh'] , n_steps, pred_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127776, 96) (127776, 672)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to define the validation set for our model #! I see this approach is not so useful, therefore I will use the train test split with shuffling to obtain the validation data. Here i am not loosing the lateest data for training my model \n",
    "def val_set(X,y):\n",
    "    X, X_val, y, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    return X, X_val, y, y_val\n",
    "    #! old approach\n",
    "    #train_size = round(len(X) * 0.8)\n",
    "    #X = X[:train_size, :]\n",
    "    #X_val = X[train_size:, :]\n",
    "    #y = y[:train_size, :]\n",
    "    #y_val = y[train_size:, :]\n",
    "    \n",
    "X, X_val, y, y_val = val_set(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25556, 96)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    " #! correction still necessary\n",
    "\n",
    "def reshape_for_LSTM(X, y, features):\n",
    "    features\n",
    "    X = X.reshape((X.shape[0], X.shape[1], features))\n",
    "    y = y.reshape((y.shape[0], y.shape[1]))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = reshape_for_LSTM(X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = reshape_for_LSTM(X_val, y_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = reshape_for_LSTM(X_test, y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25556, 672, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102220, 672, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start the modeling approach using the Long short term memory model ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store results\n",
    "history = {}\n",
    "\n",
    "# Define number of epochs and learning rate decay\n",
    "N_TRAIN = len(X)\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 2600 # total sample size = 97593 each batch 2600 samples (49 batches ) #! has to be adjusted further to improve\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay( \n",
    "    0.001,  #! please adjust and finetune ? should be fine like this \n",
    "    decay_steps=STEPS_PER_EPOCH*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "\n",
    "\n",
    "# Define optimizer used for modelling\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule, name='Adam')  # due to a warning message I used the legacy.Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path where checkpoints should be stored\n",
    "checkpoint_path = \"modeling/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0) # Set verbose != 0 if you want output during training \n",
    "\n",
    "#create a callback to stop early once there is no improvement in the loss\n",
    "cp_early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min',\n",
    "                                restore_best_weights=True,\n",
    "                                verbose = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how many output layer are needed for predicting several timestamps? Please check one output layer is enough but some of the parameters have to be adjusted,\n",
    "\n",
    "n_steps, n_features\n",
    "X.shape[1], X.shape[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reason for not having activation functions https://datascience.stackexchange.com/questions/66594/activation-function-between-lstm-layers\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell\n",
    "\n",
    "output layer structure : https://stackoverflow.com/questions/46797891/output-shape-of-lstm-model#46799544\n",
    "\n",
    "https://shiva-verma.medium.com/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.layers import Dense, Activation, Dropout, LSTM , Conv1D, MaxPooling1D, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_LSTM_model():\n",
    "    simple_LSTM = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv1D(32, kernel_size = 5, activation ='relu', input_shape =(X.shape[1], X.shape[2])),\n",
    "      tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
    "      tf.keras.layers.LSTM(45, kernel_initializer = 'uniform', return_sequences=True), # ! units are not set in stone yet \n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(y.shape[1] ,kernel_initializer = 'uniform', activation='linear') #96 to predict a day \n",
    "    ])\n",
    "\n",
    "    simple_LSTM.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.MeanAbsolutePercentageError(), \n",
    "                  metrics=[tf.keras.losses.MeanAbsolutePercentageError()])\n",
    "    return simple_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 668, 32)           192       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 334, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 334, 45)           14040     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 334, 45)           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 334, 32)           9984      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 334, 32)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 96)                3168      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35704 (139.47 KB)\n",
      "Trainable params: 35704 (139.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    simple_LSTM = get_simple_LSTM_model()\n",
    "    print(simple_LSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    history = simple_LSTM.fit(X,\n",
    "                        y,\n",
    "                        batch_size= BATCH_SIZE,\n",
    "                        validation_data= (X_val, y_val),   ##### probably best to make validation data D #! TO DO \n",
    "                        verbose=10,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS,\n",
    "                        shuffle = False, \n",
    "                        callbacks=[cp_callback, cp_early_stop]) # try without early stopping to see if there is something wrong cp_early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[375], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#with tf.device('/cpu:0'):\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#    simple_LSTM_reloaded = tf.keras.models.load_model('saved_model/simple_LSTM')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m STOP\n\u001b[1;32m      4\u001b[0m \u001b[39m# Check its architecture\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#simple_LSTM_reloaded.summary()\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "#with tf.device('/cpu:0'):\n",
    "#    simple_LSTM_reloaded = tf.keras.models.load_model('saved_model/simple_LSTM')\n",
    "#STOP\n",
    "# Check its architecture\n",
    "#simple_LSTM_reloaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [100.31908416748047,\n",
       "  100.20409393310547,\n",
       "  100.20437622070312,\n",
       "  100.14425659179688,\n",
       "  100.16031646728516,\n",
       "  100.14885711669922,\n",
       "  100.13554382324219,\n",
       "  100.1397705078125,\n",
       "  100.13341522216797,\n",
       "  100.13502502441406,\n",
       "  100.14124298095703,\n",
       "  100.1461181640625,\n",
       "  100.12493133544922],\n",
       " 'mean_absolute_percentage_error': [100.31906127929688,\n",
       "  100.2004623413086,\n",
       "  100.20076751708984,\n",
       "  100.14163970947266,\n",
       "  100.15731048583984,\n",
       "  100.14613342285156,\n",
       "  100.13301849365234,\n",
       "  100.13712310791016,\n",
       "  100.13079071044922,\n",
       "  100.1324691772461,\n",
       "  100.13842010498047,\n",
       "  100.14311981201172,\n",
       "  100.12239837646484],\n",
       " 'val_loss': [100.19440460205078,\n",
       "  100.10308074951172,\n",
       "  100.12483978271484,\n",
       "  100.13921356201172,\n",
       "  100.10443878173828,\n",
       "  100.07920837402344,\n",
       "  100.05791473388672,\n",
       "  100.05050659179688,\n",
       "  100.06433868408203,\n",
       "  100.05816650390625,\n",
       "  100.07321166992188,\n",
       "  100.09685516357422,\n",
       "  100.08013153076172],\n",
       " 'val_mean_absolute_percentage_error': [100.19107055664062,\n",
       "  100.10133361816406,\n",
       "  100.12269592285156,\n",
       "  100.13692474365234,\n",
       "  100.10262298583984,\n",
       "  100.07770538330078,\n",
       "  100.05679321289062,\n",
       "  100.04936218261719,\n",
       "  100.06282806396484,\n",
       "  100.05680847167969,\n",
       "  100.07154846191406,\n",
       "  100.0948486328125,\n",
       "  100.07843780517578]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3195/3195 [==============================] - 122s 38ms/step - loss: 100.0523 - mean_absolute_percentage_error: 100.0522\n"
     ]
    }
   ],
   "source": [
    "scores = simple_LSTM.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mean_absolute_percentage_error: 100.05%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (simple_LSTM.metrics_names[1], scores[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "than we take the splited test set and let the model predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00067435 -0.00091283  0.00026331 ... -0.00023365 -0.00037922\n",
      "  -0.00046914]\n",
      " [ 0.00065425 -0.00092837  0.00024467 ... -0.00024143 -0.00038393\n",
      "  -0.00046925]\n",
      " [ 0.0006367  -0.00093663  0.00023033 ... -0.00024459 -0.00038029\n",
      "  -0.00046591]\n",
      " ...\n",
      " [ 0.00080868 -0.00073177  0.00032274 ... -0.00010246 -0.00033343\n",
      "  -0.00038295]\n",
      " [ 0.00079773 -0.00074975  0.00031009 ... -0.00011144 -0.00033706\n",
      "  -0.00038844]\n",
      " [ 0.00079677 -0.00074376  0.00030729 ... -0.00010651 -0.00033229\n",
      "  -0.00038228]]\n"
     ]
    }
   ],
   "source": [
    "x_input = X_test\n",
    "#x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], 1))\n",
    "y_pred = simple_LSTM.predict(x_input, verbose=0)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "14/14 [==============================] - 21s 1s/step - loss: 100.0398 - mean_absolute_percentage_error: 100.0406\n",
      "test loss, test acc: [100.039794921875, 100.0406265258789]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = simple_LSTM.evaluate(X_test, y_test, batch_size=2600)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now make a new timeseries from out predicted values so we can plot them nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get all the original timestamps from our original test dataset. We splitted this dataset into features and target. \n",
    "# we used the first 672 entries to predict the next 96 so for our predicted values we will start only from index 672.\n",
    "# The following timestamps will be predicted by our model \n",
    "df_trial = test.iloc[672:].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (34368) does not match length of index (34464)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Then we make a new column containing the first prediction of our\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_trial[\u001b[39m'\u001b[39;49m\u001b[39mpredicted_values\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m y_pred[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/EES_Optimisation/.venv/lib/python3.11/site-packages/pandas/core/frame.py:3960\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3958\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3959\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3960\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/Desktop/EES_Optimisation/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4153\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4155\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4156\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4157\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4158\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4159\u001b[0m     ):\n\u001b[1;32m   4160\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4161\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/Desktop/EES_Optimisation/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4880\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4877\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4879\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4880\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4881\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/EES_Optimisation/.venv/lib/python3.11/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (34368) does not match length of index (34464)"
     ]
    }
   ],
   "source": [
    "# Then we make a new column containing the first prediction of our\n",
    "df_trial['predicted_values'] = y_pred[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solar_generation_MWh_normalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-04 00:00:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-04 00:15:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-04 00:30:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-04 00:45:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-04 01:00:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 22:45:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:00:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:15:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:30:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:45:00</th>\n",
       "      <td>-0.624547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34848 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Solar_generation_MWh_normalized\n",
       "Date                                                \n",
       "2022-06-04 00:00:00                        -0.624547\n",
       "2022-06-04 00:15:00                        -0.624547\n",
       "2022-06-04 00:30:00                        -0.624547\n",
       "2022-06-04 00:45:00                        -0.624547\n",
       "2022-06-04 01:00:00                        -0.624547\n",
       "...                                              ...\n",
       "2023-06-01 22:45:00                        -0.624547\n",
       "2023-06-01 23:00:00                        -0.624547\n",
       "2023-06-01 23:15:00                        -0.624547\n",
       "2023-06-01 23:30:00                        -0.624547\n",
       "2023-06-01 23:45:00                        -0.624547\n",
       "\n",
       "[34848 rows x 1 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred[:\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred[:1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are still not very good. It seems that there are some problems with handeling the 0 and also the seasonality. More work is needed. \n",
    "    Option 1: I will remove the seasonality from the data before it goes into the model \n",
    "    Option 2: I will include the price and weather data to make the model more robust. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now create a proper output table which can then be used for the Optimisation ###\n",
    "Now we will transform out output back into the same units as before and add them to a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_and_frame(X, y):\n",
    "    ''' The input are both our arrays X_test and the predicted y \n",
    "     1st. We will inverse transfrom the arrays to the original dimensions needed by the optimizer \n",
    "     2nd. We create a dataframe for both x_test and y_pred \n",
    "     3rd. We merge all the columns representing the timesteps into a single array in one column \n",
    "     4th. We concatenate the two dataframes into one \n",
    "    '''\n",
    "    inversed_y_pred = scaler.inverse_transform(y)\n",
    "    inversed_X_test = scaler.inverse_transform(X.reshape(X.shape[0], X.shape[1]))\n",
    "    X_test = pd.DataFrame(inversed_X_test)\n",
    "    y_pred = pd.DataFrame(inversed_y_pred)\n",
    "    X_test['input_array'] = X_test.apply(lambda row: np.array(row), axis=1)\n",
    "    y_pred['output_array'] = y_pred.apply(lambda row: np.array(row), axis=1)\n",
    "    pred = pd.concat([X_test['input_array'],y_pred['output_array']],  axis=1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m consumption_predictions\u001b[39m=\u001b[39m reverse_and_frame(X_test, y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "consumption_predictions= reverse_and_frame(X_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### include the date and time column back to the output dataframe ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is currently a dirty fix. It would eb better to use the date column from the original dataframe and concat on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_frame(x):\n",
    "    Date = [\"2022-06-01 00:00:00\"]\n",
    "    Date[0] = pd.to_datetime(Date[0])\n",
    "    Date[0] = (Date[0] + datetime.timedelta(minutes=(15 * 672)))\n",
    "    for i in range(len(x)-1):\n",
    "        Date.append(Date[i]+ datetime.timedelta(minutes=15))\n",
    "    x['Date'] = Date\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_date = add_time_frame(solar_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-12-05 23:52:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2022-06-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2022-09-06 11:56:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-12-05 23:52:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-03-06 11:48:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-06-04 23:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date\n",
       "count                34752\n",
       "mean   2022-12-05 23:52:30\n",
       "min    2022-06-08 00:00:00\n",
       "25%    2022-09-06 11:56:15\n",
       "50%    2022-12-05 23:52:30\n",
       "75%    2023-03-06 11:48:45\n",
       "max    2023-06-04 23:45:00"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_w_date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solar_predictions = df_w_date[['Date', 'output_array']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_solar_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_solar_predictions\u001b[39m.\u001b[39mto_pickle(\u001b[39m\"\u001b[39m\u001b[39m../predictions/solar_predictions.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_solar_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "df_solar_predictions.to_pickle(\"../predictions/solar_predictions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/saved_model/simple_LSTM_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/saved_model/simple_LSTM_2/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire small model as a SavedModel.\n",
    "#!mkdir -p ../models/saved_model\n",
    "simple_LSTM.save('../models/saved_model/simple_LSTM_2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short summary ###\n",
    "model is performing poorly, the overall MAPE is still around 65 % error which is helpful for our approach. Based on the output I is not able to handle the 0 very well. I will now look a bit deeper into the 0 problem. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach get rid of the seasonality beforehand "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

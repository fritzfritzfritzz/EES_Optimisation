{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach to Long-Short-Term Memory model #\n",
    " https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from statsmodels.tsa.stattools import adfuller,kpss\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "import statsmodels.graphics.tsaplots as tsaplot\n",
    "from statsmodels.tsa.holtwinters import Holt, ExponentialSmoothing, SimpleExpSmoothing\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential # intitialize the ANN\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM     # create layers\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the test train split \n",
    "in our case we can create several shorter sequences that we will use to train our model with \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/final_dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_names(df):\n",
    "    column_names = {'Photovoltaics [MWh] Original resolutions': 'Solar_generation_MWh',\n",
    "                'Photovoltaics [MW] Calculated resolutions': 'Solar_installed_MW',\n",
    "                'Total (grid load) [MWh] Original resolutions': 'Total_consumption_MWh',\n",
    "                'Germany/Luxembourg [€/MWh] Calculated resolutions': 'DE_LU_price_per_MWh',}\n",
    "    df.rename(columns=column_names, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Solar_generation_MWh</th>\n",
       "      <th>Solar_installed_MW</th>\n",
       "      <th>Total_consumption_MWh</th>\n",
       "      <th>DE_LU_price_per_MWh</th>\n",
       "      <th>normalisation_factor</th>\n",
       "      <th>Solar_generation_MWh_normalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>59.53</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42805.0</td>\n",
       "      <td>10589.75</td>\n",
       "      <td>56.10</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 22:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12945.50</td>\n",
       "      <td>95.41</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12817.75</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12539.00</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12371.00</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01 23:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>62579.0</td>\n",
       "      <td>12176.75</td>\n",
       "      <td>86.53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163680 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Solar_generation_MWh  Solar_installed_MW   \n",
       "Date                                                            \n",
       "2018-10-01 00:00:00                   0.0             42805.0  \\\n",
       "2018-10-01 00:15:00                   0.0             42805.0   \n",
       "2018-10-01 00:30:00                   0.0             42805.0   \n",
       "2018-10-01 00:45:00                   0.0             42805.0   \n",
       "2018-10-01 01:00:00                   0.0             42805.0   \n",
       "...                                   ...                 ...   \n",
       "2023-06-01 22:45:00                   0.0             62579.0   \n",
       "2023-06-01 23:00:00                   0.0             62579.0   \n",
       "2023-06-01 23:15:00                   0.0             62579.0   \n",
       "2023-06-01 23:30:00                   0.0             62579.0   \n",
       "2023-06-01 23:45:00                   0.0             62579.0   \n",
       "\n",
       "                     Total_consumption_MWh  DE_LU_price_per_MWh   \n",
       "Date                                                              \n",
       "2018-10-01 00:00:00               10589.75                59.53  \\\n",
       "2018-10-01 00:15:00               10589.75                59.53   \n",
       "2018-10-01 00:30:00               10589.75                59.53   \n",
       "2018-10-01 00:45:00               10589.75                59.53   \n",
       "2018-10-01 01:00:00               10589.75                56.10   \n",
       "...                                    ...                  ...   \n",
       "2023-06-01 22:45:00               12945.50                95.41   \n",
       "2023-06-01 23:00:00               12817.75                86.53   \n",
       "2023-06-01 23:15:00               12539.00                86.53   \n",
       "2023-06-01 23:30:00               12371.00                86.53   \n",
       "2023-06-01 23:45:00               12176.75                86.53   \n",
       "\n",
       "                     normalisation_factor  Solar_generation_MWh_normalized  \n",
       "Date                                                                        \n",
       "2018-10-01 00:00:00              0.684015                              0.0  \n",
       "2018-10-01 00:15:00              0.684015                              0.0  \n",
       "2018-10-01 00:30:00              0.684015                              0.0  \n",
       "2018-10-01 00:45:00              0.684015                              0.0  \n",
       "2018-10-01 01:00:00              0.684015                              0.0  \n",
       "...                                   ...                              ...  \n",
       "2023-06-01 22:45:00              1.000000                              0.0  \n",
       "2023-06-01 23:00:00              1.000000                              0.0  \n",
       "2023-06-01 23:15:00              1.000000                              0.0  \n",
       "2023-06-01 23:30:00              1.000000                              0.0  \n",
       "2023-06-01 23:45:00              1.000000                              0.0  \n",
       "\n",
       "[163680 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163680 entries, 0 to 163679\n",
      "Data columns (total 7 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   Date                             163680 non-null  datetime64[ns]\n",
      " 1   Solar_generation_MWh             163680 non-null  float64       \n",
      " 2   Solar_installed_MW               163680 non-null  float64       \n",
      " 3   Total_consumption_MWh            163680 non-null  float64       \n",
      " 4   DE_LU_price_per_MWh              163680 non-null  float64       \n",
      " 5   normalisation_factor             163680 non-null  float64       \n",
      " 6   Solar_generation_MWh_normalized  163680 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6)\n",
      "memory usage: 8.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a lot of samples therefore I will limit the sample size for training a bit mor\n",
    "#df = df.iloc[60000: , :]\n",
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df[['Solar_generation_MWh_normalized']], test_size=.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's scale the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Work in progress ...\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(input, n_steps, pred_size):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(input)):\n",
    "        end_ix = i + n_steps # find the end of this pattern\n",
    "        if end_ix+pred_size > len(input)-1: # check if we are beyond the sequence\n",
    "            break\n",
    "        seq_x, seq_y = input[i:end_ix], input[end_ix: end_ix+pred_size]# gather input and output parts of the pattern\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121992 121992\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "input = train\n",
    "# choose a number of time steps\n",
    "n_steps = 672\n",
    "\n",
    "# prediction size \n",
    "pred_size= 96\n",
    "# split into samples\n",
    "X, y = split_sequence(input, n_steps, pred_size)\n",
    "# summarize the data\n",
    "print(len(X), len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121992, 96, 1) (121992, 672, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to define the validation set for our model #! I see this approach is not so useful, therfore I will use the train test split with shuffling to obtain the validation data. Here i am not loosing the lateest data for training my model \n",
    "def val_set(X,y):\n",
    "    X, X_val, y, y_val = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    return X, X_val, y, y_val\n",
    "    #! old approach\n",
    "    #train_size = round(len(X) * 0.8)\n",
    "    #X = X[:train_size, :]\n",
    "    #X_val = X[train_size:, :]\n",
    "    #y = y[:train_size, :]\n",
    "    #y_val = y[train_size:, :]\n",
    "    \n",
    "X, X_val, y, y_val = val_set(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97593, 672, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "\n",
    "def reshape_for_LSTM(X, y, features):\n",
    "    features\n",
    "    X = X.reshape((X.shape[0], X.shape[1], features))\n",
    "    y = y.reshape((y.shape[0], y.shape[1]))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = reshape_for_LSTM(X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = reshape_for_LSTM(X_val, y_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24399, 672, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97593, 672, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start the modeling approach using the Long short term memory model ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store results\n",
    "history = {}\n",
    "\n",
    "# Define number of epochs and learning rate decay\n",
    "N_TRAIN = len(X)\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 2371 # total sample size = 113808 each batch 2371 samples (48 batches ) #! has to be adjusted further to improve\n",
    "STEPS_PER_EPOCH = N_TRAIN // BATCH_SIZE\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(  #! check the source \n",
    "    0.01,  #! please adjust and finetune\n",
    "    decay_steps=STEPS_PER_EPOCH*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "\n",
    "\n",
    "# Define optimizer used for modelling\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule, name='Adam')  # due to a warning message I used the legacy.Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path where checkpoints should be stored\n",
    "checkpoint_path = \"modeling/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=0) # Set verbose != 0 if you want output during training \n",
    "\n",
    "#create a callback to stop early once there is no improvement in the loss\n",
    "cp_early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0,\n",
    "                                mode='auto',\n",
    "                                baseline=None,\n",
    "                                restore_best_weights=True,\n",
    "                                verbose = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how many output layer are needed for predicting several timestamps? Please check one output layer is enough but some of the parameters have to be adjusted,\n",
    "\n",
    "n_steps, n_features\n",
    "X.shape[1], X.shape[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reason for not having activation functions https://datascience.stackexchange.com/questions/66594/activation-function-between-lstm-layers\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell\n",
    "\n",
    "output layer structure : https://stackoverflow.com/questions/46797891/output-shape-of-lstm-model#46799544\n",
    "\n",
    "https://shiva-verma.medium.com/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_LSTM_model():\n",
    "    simple_LSTM = tf.keras.Sequential([\n",
    "      tf.keras.layers.LSTM(45, kernel_initializer = 'uniform', input_shape = (X.shape[1], X.shape[2]), return_sequences=True), # ! units are not set in stone yet \n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(y.shape[1] ,kernel_initializer = 'uniform', activation='linear') #96 to predict a day \n",
    "    ])\n",
    "\n",
    "    simple_LSTM.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.MeanAbsolutePercentageError(), \n",
    "                  metrics=[tf.keras.losses.MeanAbsolutePercentageError()])\n",
    "    return simple_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 672, 45)           8460      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 672, 45)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 32)                9984      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 96)                3168      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21612 (84.42 KB)\n",
      "Trainable params: 21612 (84.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    simple_LSTM = get_simple_LSTM_model()\n",
    "    print(simple_LSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    history = simple_LSTM.fit(X,\n",
    "                        y,\n",
    "                        batch_size= BATCH_SIZE,\n",
    "                        validation_data= (X_val, y_val),   ##### probably best to make validation data D #! TO DO \n",
    "                        verbose=100,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[cp_callback, cp_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we split the test set too \n",
    "X_test, y_test = split_sequence(test, n_steps, pred_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [100.73613739013672,\n",
       "  98.66854095458984,\n",
       "  96.99805450439453,\n",
       "  95.61962890625,\n",
       "  91.35282897949219,\n",
       "  85.80809783935547,\n",
       "  81.61038970947266,\n",
       "  77.80121612548828,\n",
       "  74.92119598388672,\n",
       "  72.56488800048828,\n",
       "  72.50821685791016,\n",
       "  69.57533264160156,\n",
       "  68.83611297607422],\n",
       " 'mean_absolute_percentage_error': [100.73612213134766,\n",
       "  98.64579010009766,\n",
       "  96.99183654785156,\n",
       "  95.58751678466797,\n",
       "  91.35536193847656,\n",
       "  85.86908721923828,\n",
       "  81.67713165283203,\n",
       "  77.75575256347656,\n",
       "  74.8548812866211,\n",
       "  72.54803466796875,\n",
       "  72.52290344238281,\n",
       "  69.5459213256836,\n",
       "  68.76153564453125],\n",
       " 'val_loss': [99.49559783935547,\n",
       "  96.99715423583984,\n",
       "  96.01146697998047,\n",
       "  91.47895050048828,\n",
       "  86.82050323486328,\n",
       "  78.06043243408203,\n",
       "  75.76201629638672,\n",
       "  72.53741455078125,\n",
       "  68.71493530273438,\n",
       "  66.8681411743164,\n",
       "  65.646484375,\n",
       "  63.96110534667969,\n",
       "  64.04865264892578],\n",
       " 'val_mean_absolute_percentage_error': [99.62149047851562,\n",
       "  96.88880157470703,\n",
       "  95.9996337890625,\n",
       "  91.46997833251953,\n",
       "  86.69185638427734,\n",
       "  77.9840087890625,\n",
       "  75.63516235351562,\n",
       "  72.55809020996094,\n",
       "  68.791259765625,\n",
       "  67.1026611328125,\n",
       "  65.5768051147461,\n",
       "  63.824344635009766,\n",
       "  64.08050537109375]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.32100538],\n",
       "        [-0.3898191 ],\n",
       "        [-0.45411551],\n",
       "        ...,\n",
       "        [ 0.17424262],\n",
       "        [ 0.07983079],\n",
       "        [-0.0069016 ]],\n",
       "\n",
       "       [[-0.3898191 ],\n",
       "        [-0.45411551],\n",
       "        [-0.51163595],\n",
       "        ...,\n",
       "        [ 0.07983079],\n",
       "        [-0.0069016 ],\n",
       "        [-0.09513977]],\n",
       "\n",
       "       [[-0.45411551],\n",
       "        [-0.51163595],\n",
       "        [-0.55515273],\n",
       "        ...,\n",
       "        [-0.0069016 ],\n",
       "        [-0.09513977],\n",
       "        [-0.18066754]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        ...,\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491]],\n",
       "\n",
       "       [[-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        ...,\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491]],\n",
       "\n",
       "       [[-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        ...,\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "than we take only the first element of the splited test set and let the model predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.09513977],\n",
       "        [-0.18066754],\n",
       "        [-0.26423782],\n",
       "        [-0.3484104 ],\n",
       "        [-0.43604626],\n",
       "        [-0.50711864],\n",
       "        [-0.5697587 ],\n",
       "        [-0.60830643],\n",
       "        [-0.61899741],\n",
       "        [-0.62080433],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62005144],\n",
       "        [-0.61237201],\n",
       "        [-0.59174295],\n",
       "        [-0.54687099],\n",
       "        [-0.47082957],\n",
       "        [-0.36919004],\n",
       "        [-0.2466203 ],\n",
       "        [-0.10793882],\n",
       "        [ 0.06221327],\n",
       "        [ 0.24124941],\n",
       "        [ 0.43624672],\n",
       "        [ 0.60835632],\n",
       "        [ 0.77082898],\n",
       "        [ 0.9539307 ],\n",
       "        [ 1.10721816],\n",
       "        [ 1.26155966],\n",
       "        [ 1.39813307],\n",
       "        [ 1.52506954],\n",
       "        [ 1.62836541],\n",
       "        [ 1.77261825],\n",
       "        [ 1.96174305],\n",
       "        [ 2.1138259 ],\n",
       "        [ 2.26922144],\n",
       "        [ 2.37598058],\n",
       "        [ 2.51270457],\n",
       "        [ 2.60410485],\n",
       "        [ 2.66960588],\n",
       "        [ 2.75799462],\n",
       "        [ 2.77802137],\n",
       "        [ 2.82078526],\n",
       "        [ 2.83463835],\n",
       "        [ 2.92212363],\n",
       "        [ 2.84517874],\n",
       "        [ 2.77380521],\n",
       "        [ 2.75392904],\n",
       "        [ 2.64551354],\n",
       "        [ 2.55290864],\n",
       "        [ 2.45111854],\n",
       "        [ 2.31454514],\n",
       "        [ 2.14635055],\n",
       "        [ 1.99697809],\n",
       "        [ 1.80303482],\n",
       "        [ 1.61210309],\n",
       "        [ 1.39993999],\n",
       "        [ 1.14275435],\n",
       "        [ 0.92200836],\n",
       "        [ 0.69207717]],\n",
       "\n",
       "       [[-0.18066754],\n",
       "        [-0.26423782],\n",
       "        [-0.3484104 ],\n",
       "        [-0.43604626],\n",
       "        [-0.50711864],\n",
       "        [-0.5697587 ],\n",
       "        [-0.60830643],\n",
       "        [-0.61899741],\n",
       "        [-0.62080433],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62095491],\n",
       "        [-0.62005144],\n",
       "        [-0.61237201],\n",
       "        [-0.59174295],\n",
       "        [-0.54687099],\n",
       "        [-0.47082957],\n",
       "        [-0.36919004],\n",
       "        [-0.2466203 ],\n",
       "        [-0.10793882],\n",
       "        [ 0.06221327],\n",
       "        [ 0.24124941],\n",
       "        [ 0.43624672],\n",
       "        [ 0.60835632],\n",
       "        [ 0.77082898],\n",
       "        [ 0.9539307 ],\n",
       "        [ 1.10721816],\n",
       "        [ 1.26155966],\n",
       "        [ 1.39813307],\n",
       "        [ 1.52506954],\n",
       "        [ 1.62836541],\n",
       "        [ 1.77261825],\n",
       "        [ 1.96174305],\n",
       "        [ 2.1138259 ],\n",
       "        [ 2.26922144],\n",
       "        [ 2.37598058],\n",
       "        [ 2.51270457],\n",
       "        [ 2.60410485],\n",
       "        [ 2.66960588],\n",
       "        [ 2.75799462],\n",
       "        [ 2.77802137],\n",
       "        [ 2.82078526],\n",
       "        [ 2.83463835],\n",
       "        [ 2.92212363],\n",
       "        [ 2.84517874],\n",
       "        [ 2.77380521],\n",
       "        [ 2.75392904],\n",
       "        [ 2.64551354],\n",
       "        [ 2.55290864],\n",
       "        [ 2.45111854],\n",
       "        [ 2.31454514],\n",
       "        [ 2.14635055],\n",
       "        [ 1.99697809],\n",
       "        [ 1.80303482],\n",
       "        [ 1.61210309],\n",
       "        [ 1.39993999],\n",
       "        [ 1.14275435],\n",
       "        [ 0.92200836],\n",
       "        [ 0.69207717],\n",
       "        [ 0.48096812]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.7208104e-04  9.7919255e-04  9.4636454e-04 -1.9382272e-03\n",
      "  -1.0061392e-03  4.2466763e-03 -2.4395650e-03 -4.3593952e-03\n",
      "   1.5452302e-03  4.7673211e-03  1.6838755e-04 -2.0142121e-03\n",
      "  -1.0609244e-03 -2.5246793e-03  3.5162102e-03 -2.4984281e-03\n",
      "  -1.8573541e-04 -2.6503194e-03  1.2697493e-04 -2.2307732e-04\n",
      "  -1.2507252e-03 -1.0704120e-03  9.8839548e-05  2.0514510e-03\n",
      "   9.7309443e-04 -3.1822280e-03 -1.1050068e-03 -1.8370979e-03\n",
      "   5.2274838e-03  5.5532041e-04  2.4710987e-03 -2.6858896e-03\n",
      "   6.5505359e-04 -7.4892188e-04 -7.0136535e-04  1.7484848e-03\n",
      "  -9.4406918e-04 -2.2345120e-03  8.0291618e-04  1.4746258e-03\n",
      "  -1.9499791e-03  3.8378488e-04  3.4212316e-03 -3.3996433e-03\n",
      "  -2.2145938e-03  4.7899014e-03 -4.9913314e-04 -1.8754652e-03\n",
      "  -2.8572392e-03  6.1539892e-04  1.6520181e-03 -1.2593172e-04\n",
      "   1.7499775e-03 -1.1104214e-03  2.4176082e-03 -1.7283756e-03\n",
      "  -8.2828839e-05 -3.0896852e-03  2.1329785e-03 -2.4194177e-03\n",
      "   5.0876458e-04  6.4426399e-04 -2.1464569e-03 -3.1307290e-04\n",
      "  -1.1017355e-03  6.4058352e-04 -1.2149748e-03  2.6415850e-04\n",
      "  -3.8786656e-03  2.7946704e-03  3.9171919e-05  1.3428196e-04\n",
      "   7.7092397e-04 -1.7386521e-03  4.0086238e-03 -2.7462193e-03\n",
      "  -4.7271184e-04 -1.4617822e-04 -1.4459917e-03 -7.5577287e-04\n",
      "   1.2806441e-03 -2.6290640e-03  7.2489213e-04 -8.5616839e-04\n",
      "  -1.1900521e-05  9.8809483e-04  2.7484945e-03  5.3034752e-04\n",
      "  -2.0911277e-03  2.6896212e-03  3.5953801e-03  1.1876186e-03\n",
      "   1.3019640e-03 -3.3712781e-03 -3.9315508e-03  1.0734522e-03]\n",
      " [-5.4097414e-04  7.9785538e-04  7.9947402e-04 -1.7767105e-03\n",
      "  -8.5362548e-04  3.7532924e-03 -2.1539971e-03 -3.9685490e-03\n",
      "   1.3254052e-03  4.2495411e-03  5.0304447e-05 -1.7711469e-03\n",
      "  -1.0280352e-03 -2.2973788e-03  3.1459949e-03 -2.2969781e-03\n",
      "  -2.7049994e-04 -2.4479970e-03  9.9641591e-05 -1.8683651e-04\n",
      "  -1.2163148e-03 -9.1849890e-04  6.4763872e-06  1.8319325e-03\n",
      "   8.3082647e-04 -2.9476031e-03 -8.2539336e-04 -1.6850065e-03\n",
      "   4.6849488e-03  4.8241424e-04  2.1659224e-03 -2.3433603e-03\n",
      "   5.9519609e-04 -6.7223952e-04 -4.7233602e-04  1.5387925e-03\n",
      "  -7.6029054e-04 -2.0189548e-03  6.3370634e-04  1.2979725e-03\n",
      "  -1.6740259e-03  4.4025588e-04  3.0258368e-03 -3.1873123e-03\n",
      "  -2.0673661e-03  4.0801167e-03 -3.5859796e-04 -1.6449755e-03\n",
      "  -2.4565090e-03  6.2964554e-04  1.3974546e-03 -1.0104819e-04\n",
      "   1.5520911e-03 -1.0381300e-03  2.2489391e-03 -1.4716694e-03\n",
      "  -1.0403666e-04 -2.5741039e-03  1.7881686e-03 -2.1931801e-03\n",
      "   5.0706376e-04  6.9906830e-04 -1.9639563e-03 -3.4915222e-04\n",
      "  -9.0194592e-04  6.2948221e-04 -1.0654780e-03  2.7264422e-04\n",
      "  -3.5241742e-03  2.4606930e-03  4.9111888e-05  1.7570467e-04\n",
      "   7.2524266e-04 -1.5067110e-03  3.5113392e-03 -2.5415027e-03\n",
      "  -3.2263060e-04 -2.6189134e-04 -1.1960421e-03 -5.9474190e-04\n",
      "   9.5314713e-04 -2.4400814e-03  6.8987545e-04 -7.1670755e-04\n",
      "  -1.2202926e-05  9.7200501e-04  2.3870750e-03  3.9180758e-04\n",
      "  -1.8928291e-03  2.4587112e-03  3.0853178e-03  9.6378889e-04\n",
      "   1.1224749e-03 -2.9804707e-03 -3.5679035e-03  9.9328475e-04]]\n"
     ]
    }
   ],
   "source": [
    "x_input = X_test[:2, :]\n",
    "x_input = x_input.reshape((x_input.shape[0], x_input.shape[1], 1))\n",
    "y_pred = simple_LSTM.predict(x_input, verbose=0)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_mse(y_test, y_pred):\n",
    "    return keras.metrics.mean_absolute_percentage_error(y_test.reshape(y_test.shape[0], y_test.shape[1]), y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([54.057102, 55.348057], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_mse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/saved_model/simple_LSTM/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/saved_model/simple_LSTM/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire small model as a SavedModel.\n",
    "!mkdir -p ../models/saved_model\n",
    "simple_LSTM.save('../models/saved_model/simple_LSTM')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short summary ###\n",
    "model is performing shitty it looks like it cannot handle the seasonality at all "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach get rif of the seasonality beforehand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Solar_detrend'] = (df['Solar_generation_MWh_normalized'] - df['Solar_generation_MWh_normalized'].shift(96))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163680 entries, 0 to 163679\n",
      "Data columns (total 8 columns):\n",
      " #   Column                           Non-Null Count   Dtype         \n",
      "---  ------                           --------------   -----         \n",
      " 0   Date                             163680 non-null  datetime64[ns]\n",
      " 1   Solar_generation_MWh             163680 non-null  float64       \n",
      " 2   Solar_installed_MW               163680 non-null  float64       \n",
      " 3   Total_consumption_MWh            163680 non-null  float64       \n",
      " 4   DE_LU_price_per_MWh              163680 non-null  float64       \n",
      " 5   normalisation_factor             163680 non-null  float64       \n",
      " 6   Solar_generation_MWh_normalized  163680 non-null  float64       \n",
      " 7   Solar_detrend                    163584 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7)\n",
      "memory usage: 10.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113808 113808\n"
     ]
    }
   ],
   "source": [
    "#Split into test and train set\n",
    "train, test = train_test_split(df['Solar_detrend'], test_size=.3, shuffle=False)\n",
    "\n",
    "# define input sequence\n",
    "input = train\n",
    "# choose a number of time steps (a week)\n",
    "n_steps = 672\n",
    "\n",
    "# prediction size (we want to predict a day)\n",
    "pred_size= 96\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(input, n_steps, pred_size)\n",
    "# summarize the data\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train set into train and validation set\n",
    "X, X_val, y, y_val = val_set(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = reshape_for_LSTM(X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_LSTM_model():\n",
    "    wo_season_LSTM = tf.keras.Sequential([\n",
    "      tf.keras.layers.LSTM(45 ,kernel_initializer = 'uniform', input_shape = (X.shape[1], X.shape[2]), return_sequences=True), # ! units are not set in stone yet \n",
    "      tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tf.keras.layers.Dense(y.shape[1] ,kernel_initializer = 'uniform', activation='relu') #96 to predict a day \n",
    "    ])\n",
    "\n",
    "    wo_season_LSTM.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error')\n",
    "    return wo_season_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 672, 45)           8460      \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 32)                9984      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 96)                3168      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21612 (84.42 KB)\n",
      "Trainable params: 21612 (84.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    wo_season_LSTM = get_season_LSTM_model()\n",
    "    print(wo_season_LSTM.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Epoch 2/200\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    training_history['season_free'] = wo_season_LSTM.fit(X,\n",
    "                        y,\n",
    "                        batch_size= BATCH_SIZE,\n",
    "                        validation_data= (X_val, y_val),   ##### probably best to make validation data D #! TO DO \n",
    "                        verbose=100,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=[cp_callback, cp_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [nan, nan], 'mse': [nan, nan]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history['season_free'].history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# short Summary \n",
    "sadly I still only get nan for loss and mse. check with this in detail \n",
    "https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 48336\n  y sizes: 2\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluate on test data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m results \u001b[39m=\u001b[39m wo_season_LSTM\u001b[39m.\u001b[39;49mevaluate(X_test, y_test, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2371\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest loss, test acc:\u001b[39m\u001b[39m\"\u001b[39m, results)\n",
      "File \u001b[0;32m~/git/NeueFische/EES_Optimisation/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/git/NeueFische/EES_Optimisation/.venv/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1943\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1944\u001b[0m         label,\n\u001b[1;32m   1945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m   1946\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1947\u001b[0m         ),\n\u001b[1;32m   1948\u001b[0m     )\n\u001b[1;32m   1949\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1950\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 48336\n  y sizes: 2\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = wo_season_LSTM.evaluate(X_test, y_test, batch_size=2371)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_names(df):\n",
    "    ''' this function renames the columns to make them easier to read \n",
    "      additionally set the date as index in our dataframe'''\n",
    "    column_names = {'Photovoltaics [MWh] Original resolutions': 'Solar_generation_MWh',\n",
    "                'Photovoltaics [MW] Calculated resolutions': 'Solar_installed_MW',\n",
    "                'Total (grid load) [MWh] Original resolutions': 'Total_consumption_MWh',\n",
    "                'Germany/Luxembourg [â‚¬/MWh] Calculated resolutions': 'DE_LU_price_per_MWh',}\n",
    "    df.rename(columns=column_names, inplace=True)\n",
    "    #df.set_index('Date', inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_timeseries(df, target):\n",
    "    ''' In the first part we select the train and test data.\n",
    "    In the second per the columns we want to use for our predictions '''\n",
    "    \n",
    "    test = df[df.Date >= '2022-06-01']\n",
    "    train = df[df.Date < '2022-06-01'] #alternatively use 2022-05-25\n",
    "\n",
    "    # now we select the columns we want to use for our predictions\n",
    "\n",
    "    test = test[target]\n",
    "    train = train[target]\n",
    "    return test, train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samller samples to feed into the LSTM\n",
    "def split_sequence(input, n_steps, pred_size, target = []):\n",
    "    ''' This function will split our timeseries into supervised timeseries snipets. \n",
    "    input = dataframe to be split\n",
    "    n_steps = length of the X_variable \n",
    "    pred_size = length of the y_variable\n",
    "    target\n",
    "    target = list of targets to be split\n",
    "    At the same time we will collect the corresponding timestamps in two additional arrays '''\n",
    "    input_array = input[target]\n",
    "    date_array = input['Date']\n",
    "\n",
    "    x_index, y_index = list(), list()\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(input_array)):\n",
    "        end_ix = i + n_steps # find the end of this pattern\n",
    "        if end_ix+pred_size > len(input)-1: # check if we are beyond the sequence\n",
    "            break\n",
    "        seq_x, seq_y = input_array[i:end_ix], input_array[end_ix: end_ix+pred_size]# gather input and output parts of the pattern\n",
    "        ind_x, ind_y = date_array[i:end_ix], date_array[end_ix: end_ix+pred_size]# gather input and output Dates of the pattern\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        x_index.append(ind_x)\n",
    "        y_index.append(ind_y)\n",
    "\n",
    "    \n",
    "    return np.array(x), np.squeeze(np.array(y)), np.array(x_index), np.squeeze(np.array(y_index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/final_dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['Date', 'Solar_generation_MWh_normalized']\n",
    "\n",
    "test, train = test_train_timeseries(df, target)\n",
    "test.to_pickle('../data/test.pkl')\n",
    "train.to_pickle('../data/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "input = train\n",
    "# choose a number of time steps\n",
    "n_steps = 672\n",
    "# prediction size \n",
    "pred_size= 96\n",
    "\n",
    "target = ['Solar_generation_MWh_normalized']\n",
    "\n",
    "# split into samples\n",
    "X, y, X_train_index, Y_train_index = split_sequence(input, n_steps, pred_size, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, X_test_index, Y_test_index = split_sequence(test , n_steps, pred_size, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe with the input sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make a new df containing the input arrays and the timestempt from when we want to predict \n",
    "\n",
    "def input_df(X, index, y):\n",
    "    df_1 = pd.DataFrame(X.reshape(X.shape[0], X.shape[1]))\n",
    "    df_2 = pd.DataFrame(y)\n",
    "    df_1['input'] = df_1.apply(lambda row: np.array(row), axis =1)\n",
    "    df_2['output'] = df_2.apply(lambda row: np.array(row), axis =1)\n",
    "    df_date = pd.DataFrame(index[:, -1], columns = ['Date'])\n",
    "    df_date['input'] = df_1['input'] \n",
    "    df_date['output'] = df_2['output']\n",
    "    df_date['input'] = df_date['input'].apply(lambda cell: cell.reshape(1, 672, 1))\n",
    "    return df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = input_df(X_test, X_test_index, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a single input sequence \n",
    "input = df_input.iloc[1, 1].tolist()\n",
    "\n",
    "output = df_input.iloc[1, 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the single input sequence as json file \n",
    "with open('../data/input.json', 'w') as json_file:\n",
    "    json.dump(input, json_file)\n",
    "\n",
    "with open('../data/output.json', 'w') as json_file:\n",
    "    json.dump(output, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.to_json('../data/test_input_solar.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
